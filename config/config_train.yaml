seed: 13

audio:
  sr: 44100  # target sample rate
  dur_samples: ${pow:2,15}
  
debug: True  # log_dir = 'logs/debug' if True
project_dir: ${oc.env:HOME}/cosi
log_path:
  "${hydra:job.name}/\
   ${hydra:runtime.choices.features}_\
   ${hydra:runtime.choices.model}/\
   ${get_basename:${hydra:runtime.choices.net}}/\
   ${hydra:runtime.choices.datamodule}/\
   ${now:%Y-%m-%d_%H-%M-%S}"
log_dir:
  "${project_dir}/logs/\
  ${log_path:${log_path}, ${debug}}"
checkpoints_dir: ${log_dir}/checkpoints
outputs_dir: ${log_dir}/outputs

hydra:
  run:
    dir: ${log_dir}
  output_subdir: hydra
  sweep:
    dir: ${log_dir}/sweeps
    
wandb:
  save_dir: ${log_dir}
  project: cosi
  run: pilot

defaults:
  - features: jtfs
  - datamodule: sol
  - transform: default
  - net: autoencoder/conv
  - model: autoencoder
  - optim: default
  - logger: wandb
  - callbacks: default
  - _self_

features:
  sr: ${audio.sr}
  device: cuda

datamodule:
  batch_size: 32
  num_workers: 8
  transform: ${transform}
  # sampler:
  # collate_fn:

net:
  sr: ${audio.sr}

model:
  loss_fn:
    _target_: torch.nn.MSELoss
  loss_weights:
    recon: 1.0

visualize:
  n_components: 2

# trainer:
#   _target_: lightning.pytorch.Trainer
#   deterministic: True
#   accelerator: gpu
#   devices: 1
#   max_epochs: 100
#   precision: 16
#   callbacks:
#     # - early_stopping:
#     #     monitor: val_loss
#     #     patience: 10
#     #     mode: min
#     # - model_checkpoint:
#     #     monitor: val_loss
#     #     mode: min
#     #     save_top_k: 1
#     #     filename: "{epoch}-{val_loss:.2f}"
#     # - lr_monitor:
#     #     logging_interval: step
#   early_stopping: false
#   logger: wandb
#   log_every_n_steps: 50